{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrDPvx5u/GMR7mFNI1GE/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trinayasri/new/blob/main/NLP_word_sentence%2Cparagraph_tokenizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXLBr--_iSv-",
        "outputId": "43566c6f-6f16-4580-838d-86c81086e22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "text = \"\"\"\n",
        "Artificial Intelligence is transforming healthcare. It hepls doctors diagnose early.\n",
        "Moreover,AI enables personalized treatment for each patient.\n",
        "\n",
        "This shift can improve outcomes and reduces costs.Many hospitals now rely on AI-powered systems.\n",
        "\"\"\"\n",
        "# word Tokenizer\n",
        "word_tokens = word_tokenize(text)\n",
        "print(\"word tokens:\")\n",
        "print(word_tokens)\n",
        "\n",
        "# sentence tokenizer\n",
        "sent_tokens = sent_tokenize(text)\n",
        "print(\"sentence tokens:\")\n",
        "for i,sent in enumerate(sent_tokens, 1):\n",
        "  print(f\"(i): (sent)\")\n",
        "\n",
        "#paragraph Tokenizer (Manual Split)\n",
        "paragraphs = [p.strip() for p in text.strip().split('\\n\\n') if p]\n",
        "print(\"paragraph tokens:\")\n",
        "for i,para in enumerate(paragraphs, 1):\n",
        "  print(f\"paragraph {i}: {para}\")\n",
        "\n",
        "text = \"\"\"Artificial Intelligence is transforming healthcare. It helps doctors diagnose early.\n",
        "Moreover, AI enables personalized treatment for each patient.\n",
        "This shift can improve outcomes and reduces costs. Many hospitals now rely on AI-powered systems.\"\"\"\n",
        "\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "\n",
        "total_words = len(words)\n",
        "\n",
        "words_lower = [word.lower().strip('.,') for word in words]\n",
        "\n",
        "\n",
        "distinct_words = len(set(words_lower))\n",
        "\n",
        "print(f\"Total number of words: {total_words}\")\n",
        "print(f\"Number of distinct words: {distinct_words}\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwHCQ66Jif98",
        "outputId": "4c854852-7837-4a51-e599-8e09b57fc835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word tokens:\n",
            "['Artificial', 'Intelligence', 'is', 'transforming', 'healthcare', '.', 'It', 'hepls', 'doctors', 'diagnose', 'early', '.', 'Moreover', ',', 'AI', 'enables', 'personalized', 'treatment', 'for', 'each', 'patient', '.', 'This', 'shift', 'can', 'improve', 'outcomes', 'and', 'reduces', 'costs.Many', 'hospitals', 'now', 'rely', 'on', 'AI-powered', 'systems', '.']\n",
            "sentence tokens:\n",
            "(i): (sent)\n",
            "(i): (sent)\n",
            "(i): (sent)\n",
            "(i): (sent)\n",
            "paragraph tokens:\n",
            "paragraph 1: Artificial Intelligence is transforming healthcare. It hepls doctors diagnose early.\n",
            "Moreover,AI enables personalized treatment for each patient.\n",
            "paragraph 2: This shift can improve outcomes and reduces costs.Many hospitals now rely on AI-powered systems.\n",
            "Total number of words: 33\n",
            "Number of distinct words: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}